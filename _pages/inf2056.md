---
layout: archive
title: "INF2056 - Distributed Algorithms"
permalink: /INF2056/
author_profile: true
---

{% include base_path %}

This page is dedicated to the INF2056 - Distributed Algorithms course. 



<details markdown=1>
<summary><b>Simulação de Drone Líder e Seguidor com GrADyS-SIM NextGen</b></summary>

* Neste repositório (https://github.com/sebastianquispearias/test_01_gradys-sim-nextgen), implementei uma simulação simples utilizando o framework GrADyS-SIM NextGen com o objetivo de me familiarizar com suas  funcionalidades. Na simulação, um drone líder (SquareRouteDrone) segue uma rota quadrada e transmite sua posição por meio de plugins de missão e liderança, enquanto um drone seguidor (FollowingDrone) monitora e acompanha esse líder.  É possível visualizar esse comportamento se a linha abaixo for descomentada no `drone_simulation.py`:

```builder.add_handler(VisualizationHandler(VisualizationConfiguration(x_range=(-50, 150), y_range=(-50, 150), z_range=(0, 100), open_browser=True)))```



 
</details>
<br />



<details markdown=1>
<summary><b>Mapeamento e Detecção de Pessoas com Swarm de Drones</b></summary>

A ideia central do nosso projeto é desenvolver um sistema distribuído para missões de busca e salvamento (SAR) que permita construir um mapa global com todos os pontos de interesse (POIs) detectados (neste caso, pessoas), utilizando dados capturados a bordo dos drones. Cada drone, equipado com uma câmera (como a Raspberry Pi HQ Camera) e com informações de GPS armazenadas nos metadados EXIF, processa localmente as imagens para identificar automaticamente os POIs, utilizando modelos de detecção de objetos (por exemplo, YOLO ou alternativas). Essa detecção gera um output com as coordenadas geográficas de cada pessoa encontrada, que são posteriormente compartilhadas entre todos os drones do enxame.

Inicialmente, o swarm de drones irá viajando em uma formação em "V", realizando uma rota determinada, e posteriormente (com todos os POIs já mapeados), o sistema aplicará uma função objetivo para minimizar a distância e o tempo de voo, permitindo que cada drone seja designado para visitar um ou mais pontos de interesse de maneira otimizada. Essa abordagem colaborativa evita soluções subótimas que ocorreriam se os drones operassem de forma isolada, e também otimiza os recursos durante a missão.

Um dos pontos que geram mais preocupação são as seguintes situações: se dois drones detectam a mesma pessoa, mas, devido a pequenas diferenças de tempo ou erros de medição, cada um gera coordenadas ligeiramente diferentes para esse POI. Nesta situação, em lugar de ter 1 POI, teríamos 2 POIs. Por outro lado, se um drone detecta uma vítima e outro não a detecta, o sistema pode perder a chance de registrar esse POI como válido [não estou seguro sobre o que deveria acontecer nessa situação]. Por esse motivo, assumiremos inicialmente que os POIs são fixos e, posteriormente, exploraremos soluções para não assumir necessariamente isso (talvez utilizando filtro de Kalman ou técnicas como DBSCAN).

Finalmente, estes são alguns dos papers que serão estudados e que, se for pertinente, poderão ser usados em nossa solução:

[1]Real Time Embedded Image Processing System for Points of Interest Detection for Autonomous Unmanned Aerial Vehicles – Freitas et al.

[2]Robot Swarm Navigation and Victim Detection Using Rendezvous Consensus in Search and Rescue Operations – Cardona et al.

[3]A Survey of Deep Learning Techniques for Vehicle Detection from UAV Images – Srivastava et al.

[4]Unmanned Aerial Vehicles (UAVs): Practical Aspects, Applications, Open Challenges, Security Issues, and Future Trends – Mohsan et al.

[5]Vehicle Detection from UAV Imagery with Deep Learning: A Review – Bouguettaya et al.


 
</details>
<br />
